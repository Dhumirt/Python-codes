{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typing-extensions>=4.0.0 (from beautifulsoup4)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.2.3-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\intel\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\intel\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.5 MB 4.3 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.8/11.5 MB 4.4 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.9/11.5 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.7/11.5 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.7/11.5 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.8/11.5 MB 4.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.8/11.5 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.3/11.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.3/11.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.1/11.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.7/11.5 MB 3.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.4/11.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.0/11.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.2/11.5 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.0/11.5 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 3.3 MB/s eta 0:00:00\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl (102 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading numpy-2.2.3-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.6 MB 3.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.6/12.6 MB 3.0 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.1/12.6 MB 3.0 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.9/12.6 MB 3.1 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.9/12.6 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.2/12.6 MB 2.8 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.7/12.6 MB 2.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 6.3/12.6 MB 3.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.9/12.6 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.7/12.6 MB 3.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.5/12.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.6 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.8/12.6 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.6 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 2.5 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: pytz, urllib3, tzdata, typing-extensions, soupsieve, numpy, idna, charset-normalizer, certifi, requests, pandas, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.13.3 certifi-2025.1.31 charset-normalizer-3.4.1 idna-3.10 numpy-2.2.3 pandas-2.2.3 pytz-2025.1 requests-2.32.3 soupsieve-2.6 typing-extensions-4.12.2 tzdata-2025.1 urllib3-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched succesfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "\n",
    "url = \"http://quotes.toscrape.com/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "#check if request was succesful\n",
    "if response.status_code==200:\n",
    "    print(\"Page fetched succesfully\")\n",
    "else:\n",
    "    print(\"Fail to fetch page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <title>\n",
      "   Quotes to Scrape\n",
      "  </title>\n",
      "  <link href=\"/static/bootstrap.min.css\" rel=\"stylesheet\"/>\n",
      "  <link href=\"/static/main.css\" rel=\"stylesheet\"/>\n",
      " </head>\n",
      " <body>\n",
      "  <div class=\"container\">\n",
      "   <div class=\"row header-box\">\n",
      "    <div class=\"col-md-8\">\n",
      "     <h1>\n",
      "      <a href=\"/\" style=\"text-decoration: none\">\n",
      "       Quotes to Scrape\n",
      "      </a>\n",
      "     </h1>\n",
      "    </div>\n",
      "    <div class=\"col-md-4\">\n",
      "     <p>\n",
      "      <a href=\"/login\">\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "#Print formatted html(optional)\n",
    "print(soup.prettify()[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quote:-“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "Author:-Albert Einstein\n",
      "--------------------------------------------------\n",
      "Quote:-“It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "Author:-J.K. Rowling\n",
      "--------------------------------------------------\n",
      "Quote:-“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "Author:-Albert Einstein\n",
      "--------------------------------------------------\n",
      "Quote:-“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "Author:-Jane Austen\n",
      "--------------------------------------------------\n",
      "Quote:-“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "Author:-Marilyn Monroe\n",
      "--------------------------------------------------\n",
      "Quote:-“Try not to become a man of success. Rather become a man of value.”\n",
      "Author:-Albert Einstein\n",
      "--------------------------------------------------\n",
      "Quote:-“It is better to be hated for what you are than to be loved for what you are not.”\n",
      "Author:-André Gide\n",
      "--------------------------------------------------\n",
      "Quote:-“I have not failed. I've just found 10,000 ways that won't work.”\n",
      "Author:-Thomas A. Edison\n",
      "--------------------------------------------------\n",
      "Quote:-“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "Author:-Eleanor Roosevelt\n",
      "--------------------------------------------------\n",
      "Quote:-“A day without sunshine is like, you know, night.”\n",
      "Author:-Steve Martin\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "quotes = soup.find_all('span', class_='text')\n",
    "authors = soup.find_all('small', class_='author')\n",
    "\n",
    "#Print extracted data \n",
    "for i in range(len(quotes)):\n",
    "    print(f\"Quote:-{quotes[i].text}\")\n",
    "    print(f\"Author:-{authors[i].text}\")\n",
    "    print(\"-\"*50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to quotes.csv!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {\"Quote\": [q.text for q in quotes], \"Author\": [a.text for a in authors]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv(\"quotes.csv\", index=False)\n",
    "print(\"Data saved to quotes.csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped Page 1\n",
      "Scraped Page 2\n",
      "Scraped Page 3\n",
      "Scraped Page 4\n",
      "Scraped Page 5\n",
      "Scraped Page 6\n",
      "Scraped Page 7\n",
      "Scraped Page 8\n",
      "Scraped Page 9\n",
      "Scraped Page 10\n",
      "All pages scraped and saved to all_quotes.csv!\n"
     ]
    }
   ],
   "source": [
    "page = 1\n",
    "all_quotes = []\n",
    "all_authors = []\n",
    "\n",
    "while True:\n",
    "    url = f\"http://quotes.toscrape.com/page/{page}/\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if \"No quotes found!\" in response.text:  # Stop if no more pages\n",
    "        break\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    quotes = soup.find_all(\"span\", class_=\"text\")\n",
    "    authors = soup.find_all(\"small\", class_=\"author\")\n",
    "\n",
    "    all_quotes.extend([q.text for q in quotes])\n",
    "    all_authors.extend([a.text for a in authors])\n",
    "\n",
    "    print(f\"Scraped Page {page}\")\n",
    "    page += 1\n",
    "\n",
    "df = pd.DataFrame({\"Quote\": all_quotes, \"Author\": all_authors})\n",
    "df.to_csv(\"all_quotes.csv\", index=False)\n",
    "print(\"All pages scraped and saved to all_quotes.csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "\n",
    "url = \"http://quotes.toscrape.com/\"\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "print(response.status_code) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
